{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 37484,
          "sourceType": "datasetVersion",
          "datasetId": 29414,
          "isSourceIdPinned": false
        }
      ],
      "dockerImageVersionId": 31154,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Pr_Project",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "shayanfazeli_heartbeat_path = kagglehub.dataset_download('shayanfazeli/heartbeat')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "KG1jWhI9zdhq"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing dataset from kaggle\n",
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"shayanfazeli/heartbeat\")\n",
        "print(\"Path to dataset files:\", path)\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T09:38:24.894507Z",
          "iopub.execute_input": "2025-12-06T09:38:24.895198Z",
          "iopub.status.idle": "2025-12-06T09:38:24.998235Z",
          "shell.execute_reply.started": "2025-12-06T09:38:24.895173Z",
          "shell.execute_reply": "2025-12-06T09:38:24.997667Z"
        },
        "id": "iu-uDNptzdht"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Installing tensorflow\n",
        "!pip install --upgrade tensorflow"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T09:38:28.731839Z",
          "iopub.execute_input": "2025-12-06T09:38:28.732108Z",
          "iopub.status.idle": "2025-12-06T09:38:32.298256Z",
          "shell.execute_reply.started": "2025-12-06T09:38:28.732088Z",
          "shell.execute_reply": "2025-12-06T09:38:32.297502Z"
        },
        "id": "ROimM_cgzdht"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Here we are importing the basic python and data analysis libraries\n",
        "import os, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "# Imported the machine learning utilities from sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, BatchNormalization, Dropout, Dense, Flatten\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "print(\"TensorFlow imported successfully, version:\", tf.__version__)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T09:38:38.105364Z",
          "iopub.execute_input": "2025-12-06T09:38:38.106167Z",
          "iopub.status.idle": "2025-12-06T09:38:38.147233Z",
          "shell.execute_reply.started": "2025-12-06T09:38:38.106139Z",
          "shell.execute_reply": "2025-12-06T09:38:38.146486Z"
        },
        "id": "FnJEDCnjzdhu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Paths of Train and Test csv files\n",
        "TRAIN_CSV = \"/kaggle/input/heartbeat/mitbih_train.csv\"\n",
        "TEST_CSV  = \"/kaggle/input/heartbeat/mitbih_test.csv\"\n",
        "\n",
        "assert os.path.exists(TRAIN_CSV), \"Train CSV not found. Did you Add Data (shayanfazeli/heartbeat)?\"\n",
        "assert os.path.exists(TEST_CSV), \"Test CSV not found. Did you Add Data (shayanfazeli/heartbeat)?\"\n",
        "#It will read csv files using pandas\n",
        "train_df = pd.read_csv(TRAIN_CSV, header=None)\n",
        "test_df  = pd.read_csv(TEST_CSV,  header=None)\n",
        "\n",
        "print(\"Train shape:\", train_df.shape)  # expected ~ (87554, 188)\n",
        "print(\"Test shape:\",  test_df.shape)   # expected ~ (21892, 188)\n",
        "\n",
        "# Last column is label; first 187 columns are samples\n",
        "N_SAMPLES = train_df.shape[1] - 1\n",
        "print(\"Samples per beat:\", N_SAMPLES)\n",
        "train_df.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T09:38:42.747441Z",
          "iopub.execute_input": "2025-12-06T09:38:42.748129Z",
          "iopub.status.idle": "2025-12-06T09:38:47.850842Z",
          "shell.execute_reply.started": "2025-12-06T09:38:42.748103Z",
          "shell.execute_reply": "2025-12-06T09:38:47.850113Z"
        },
        "id": "dnZK1z8Kzdhu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the features from column 0 to N-1\n",
        "X_train_all = train_df.iloc[:, :N_SAMPLES].values.astype(np.float32)\n",
        "# Extract the labels from column 0 to N\n",
        "y_train_all = train_df.iloc[:,  N_SAMPLES].values.astype(int)\n",
        "\n",
        "X_test = test_df.iloc[:, :N_SAMPLES].values.astype(np.float32)\n",
        "y_test = test_df.iloc[:,  N_SAMPLES].values.astype(int)\n",
        "\n",
        "# Normalization for keeping stable\n",
        "X_train_all = (X_train_all - X_train_all.min(axis=1, keepdims=True)) / (X_train_all.ptp(axis=1, keepdims=True) + 1e-8)\n",
        "X_test      = (X_test      - X_test.min(axis=1, keepdims=True))      / (X_test.ptp(axis=1, keepdims=True) + 1e-8)\n",
        "\n",
        "# Train/Validation split from training set\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_all, y_train_all, test_size=0.15, random_state=SEED, stratify=y_train_all\n",
        ")\n",
        "\n",
        "# Reshape for 1D CNN: (n_samples, timesteps, channels)\n",
        "X_train = X_train[..., None]\n",
        "X_val   = X_val[..., None]\n",
        "X_test  = X_test[..., None]\n",
        "\n",
        "# One-hot encoding\n",
        "num_classes = len(np.unique(y_train_all))\n",
        "y_train_cat = to_categorical(y_train, num_classes)\n",
        "y_val_cat   = to_categorical(y_val,   num_classes)\n",
        "y_test_cat  = to_categorical(y_test,  num_classes)\n",
        "\n",
        "print(f\"Classes: {num_classes} | Shapes -> X_train: {X_train.shape}, y_train: {y_train_cat.shape}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T09:39:29.226098Z",
          "iopub.execute_input": "2025-12-06T09:39:29.226736Z",
          "iopub.status.idle": "2025-12-06T09:39:29.554531Z",
          "shell.execute_reply.started": "2025-12-06T09:39:29.226714Z",
          "shell.execute_reply": "2025-12-06T09:39:29.55383Z"
        },
        "id": "xtinZS-7zdhv"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting  one random sample per class from training set\n",
        "plt.figure(figsize=(12, 6))\n",
        "classes = np.unique(y_train_all)\n",
        "for i, c in enumerate(classes):\n",
        "    idx = np.where(y_train == c)[0][0]\n",
        "    plt.plot(X_train[idx].squeeze(), label=f\"class {c}\")\n",
        "plt.title(\"Example ECG beats (one per class)\")\n",
        "plt.xlabel(\"Sample index (0..186)\")\n",
        "plt.ylabel(\"Normalized amplitude\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T09:39:37.525276Z",
          "iopub.execute_input": "2025-12-06T09:39:37.525627Z",
          "iopub.status.idle": "2025-12-06T09:39:37.741723Z",
          "shell.execute_reply.started": "2025-12-06T09:39:37.525591Z",
          "shell.execute_reply": "2025-12-06T09:39:37.74102Z"
        },
        "id": "gwQkpOhYzdhv"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# We are computing the class weights for imbalaned class\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight=\"balanced\",\n",
        "    classes=classes,\n",
        "    y=y_train\n",
        ")\n",
        "class_weights = {int(c): w for c, w in zip(classes, class_weights)}\n",
        "class_weights"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T09:39:43.924903Z",
          "iopub.execute_input": "2025-12-06T09:39:43.925511Z",
          "iopub.status.idle": "2025-12-06T09:39:43.943618Z",
          "shell.execute_reply.started": "2025-12-06T09:39:43.925486Z",
          "shell.execute_reply": "2025-12-06T09:39:43.942906Z"
        },
        "id": "F4JG1PlQzdhw"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracts local patterns and uses RELU to stabilize\n",
        "#Uses MaxPoolong to reduce dimensions\n",
        "def make_model(input_len=187, n_classes=5):\n",
        "    model = Sequential([\n",
        "        Conv1D(32, kernel_size=7, activation='relu', padding='same', input_shape=(input_len,1)),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(2),\n",
        "\n",
        "        Conv1D(64, kernel_size=5, activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(2),\n",
        "\n",
        "        Conv1D(128, kernel_size=3, activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(2),\n",
        "\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.4),\n",
        "        Dense(n_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = make_model(N_SAMPLES, num_classes)\n",
        "model.summary()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T09:39:48.279071Z",
          "iopub.execute_input": "2025-12-06T09:39:48.27965Z",
          "iopub.status.idle": "2025-12-06T09:39:48.391497Z",
          "shell.execute_reply.started": "2025-12-06T09:39:48.279626Z",
          "shell.execute_reply": "2025-12-06T09:39:48.390947Z"
        },
        "id": "e4gJuKTRzdhy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 40\n",
        "BATCH  = 256\n",
        "\n",
        "ckpt_path = \"/kaggle/working/ecg_cnn_best.keras\"\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor=\"val_loss\", patience=6, restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, verbose=1),\n",
        "    ModelCheckpoint(ckpt_path, monitor=\"val_loss\", save_best_only=True, verbose=1)\n",
        "]\n",
        "#Training the model\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train_cat,\n",
        "    validation_data=(X_val, y_val_cat),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH,\n",
        "    class_weight=class_weights,\n",
        "    verbose=1,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T09:39:55.009923Z",
          "iopub.execute_input": "2025-12-06T09:39:55.010197Z",
          "iopub.status.idle": "2025-12-06T09:41:30.037897Z",
          "shell.execute_reply.started": "2025-12-06T09:39:55.010177Z",
          "shell.execute_reply": "2025-12-06T09:41:30.037348Z"
        },
        "id": "XFJQxifXzdhz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting the graphs for accuracy and loss\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(history.history['accuracy'], label='train_acc')\n",
        "plt.plot(history.history['val_accuracy'], label='val_acc')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epoch'); plt.ylabel('Acc'); plt.legend(); plt.show()\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(history.history['loss'], label='train_loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend(); plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T09:41:41.340369Z",
          "iopub.execute_input": "2025-12-06T09:41:41.341079Z",
          "iopub.status.idle": "2025-12-06T09:41:41.663974Z",
          "shell.execute_reply.started": "2025-12-06T09:41:41.341057Z",
          "shell.execute_reply": "2025-12-06T09:41:41.6633Z"
        },
        "id": "LtKqTR-vzdh0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluating the trained model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test_cat, verbose=0)\n",
        "print(f\"Test Accuracy: {test_acc*100:.2f}% | Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "# Predictions\n",
        "y_prob = model.predict(X_test, verbose=0)\n",
        "y_pred = np.argmax(y_prob, axis=1)\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, digits=4))\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred, labels=classes)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
        "fig, ax = plt.subplots(figsize=(6,5))\n",
        "disp.plot(ax=ax, values_format='d', colorbar=False)\n",
        "plt.title(\"Confusion Matrix (Test)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T09:41:46.554912Z",
          "iopub.execute_input": "2025-12-06T09:41:46.555442Z",
          "iopub.status.idle": "2025-12-06T09:41:51.02392Z",
          "shell.execute_reply.started": "2025-12-06T09:41:46.555421Z",
          "shell.execute_reply": "2025-12-06T09:41:51.023213Z"
        },
        "id": "NcE6nUlHzdh0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the model and predictions\n",
        "final_model_path = \"/kaggle/working/ecg_cnn_final.keras\"\n",
        "model.save(final_model_path)\n",
        "\n",
        "preds_path = \"/kaggle/working/test_predictions.csv\"\n",
        "pd.DataFrame({\n",
        "    \"y_true\": y_test,\n",
        "    \"y_pred\": y_pred\n",
        "}).to_csv(preds_path, index=False)\n",
        "\n",
        "print(\"Saved:\", final_model_path, \"and\", preds_path)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T09:42:01.544969Z",
          "iopub.execute_input": "2025-12-06T09:42:01.545653Z",
          "iopub.status.idle": "2025-12-06T09:42:01.638453Z",
          "shell.execute_reply.started": "2025-12-06T09:42:01.545631Z",
          "shell.execute_reply": "2025-12-06T09:42:01.637766Z"
        },
        "id": "QooddHKgzdh1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# pick one sample index\n",
        "index = 42\n",
        "\n",
        "sample_signal = X_test[index]       # shape: (187, 1)\n",
        "true_label = y_test[index]\n",
        "\n",
        "# visualize it\n",
        "plt.figure(figsize=(10,3))\n",
        "plt.plot(sample_signal)\n",
        "plt.title(f\"Example ECG Signal (True label = {true_label})\")\n",
        "plt.xlabel(\"Sample index (0–186)\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T09:42:05.084429Z",
          "iopub.execute_input": "2025-12-06T09:42:05.085048Z",
          "iopub.status.idle": "2025-12-06T09:42:05.230124Z",
          "shell.execute_reply.started": "2025-12-06T09:42:05.085026Z",
          "shell.execute_reply": "2025-12-06T09:42:05.229433Z"
        },
        "id": "0bQA9V9Hzdh1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Model expects shape (1, 187, 1) — add batch dimension\n",
        "sample_signal = sample_signal.reshape(1, 187, 1)\n",
        "\n",
        "# Make prediction\n",
        "prediction = model.predict(sample_signal)\n",
        "\n",
        "# Get the class with the highest probability\n",
        "predicted_class = np.argmax(prediction)\n",
        "confidence = np.max(prediction)\n",
        "\n",
        "print(f\"Predicted class: {predicted_class} (confidence = {confidence*100:.2f}%)\")\n",
        "print(f\"True class: {true_label}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T09:42:11.444367Z",
          "iopub.execute_input": "2025-12-06T09:42:11.444706Z",
          "iopub.status.idle": "2025-12-06T09:42:11.802519Z",
          "shell.execute_reply.started": "2025-12-06T09:42:11.444684Z",
          "shell.execute_reply": "2025-12-06T09:42:11.801807Z"
        },
        "id": "lmjPbdPCzdh1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = {\n",
        "    0: \"Normal (N)\",\n",
        "    1: \"Supraventricular (S)\",\n",
        "    2: \"Ventricular (V)\",\n",
        "    3: \"Fusion (F)\",\n",
        "    4: \"Unknown (Q)\"\n",
        "}\n",
        "\n",
        "print(f\"Model Prediction: {class_names[predicted_class]} ({confidence*100:.2f}%)\")\n",
        "print(f\"Actual Label: {class_names[true_label]}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T09:06:08.510462Z",
          "iopub.execute_input": "2025-12-06T09:06:08.511057Z",
          "iopub.status.idle": "2025-12-06T09:06:08.515176Z",
          "shell.execute_reply.started": "2025-12-06T09:06:08.511035Z",
          "shell.execute_reply": "2025-12-06T09:06:08.514433Z"
        },
        "id": "bAO345Aszdh2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NON-DL MODEL**"
      ],
      "metadata": {
        "id": "rkZ_hxm1zdh2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet PyWavelets xgboost"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T09:42:18.604111Z",
          "iopub.execute_input": "2025-12-06T09:42:18.604398Z",
          "iopub.status.idle": "2025-12-06T09:42:21.669762Z",
          "shell.execute_reply.started": "2025-12-06T09:42:18.604379Z",
          "shell.execute_reply": "2025-12-06T09:42:21.668856Z"
        },
        "id": "7k9R3BgAzdh3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Here we imported the dataset from kaggle\n",
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"shayanfazeli/heartbeat\")\n",
        "print(\"Path to dataset files:\",path)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T09:42:52.175151Z",
          "iopub.execute_input": "2025-12-06T09:42:52.175697Z",
          "iopub.status.idle": "2025-12-06T09:42:52.27799Z",
          "shell.execute_reply.started": "2025-12-06T09:42:52.175671Z",
          "shell.execute_reply": "2025-12-06T09:42:52.277379Z"
        },
        "id": "ENBpdmrYzdh3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# We imported the basic python and data analysis libraries\n",
        "import os, random, math, joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Imported the machine learning utilities from sklearn\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "import pywt\n",
        "from scipy.stats import skew, kurtosis\n",
        "from scipy.signal import find_peaks"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T09:43:18.074292Z",
          "iopub.execute_input": "2025-12-06T09:43:18.075028Z",
          "iopub.status.idle": "2025-12-06T09:43:18.079961Z",
          "shell.execute_reply.started": "2025-12-06T09:43:18.075005Z",
          "shell.execute_reply": "2025-12-06T09:43:18.079006Z"
        },
        "id": "vHOlTpRBzdh4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths of Train and Test csv files\n",
        "DATA_PATH = \"/kaggle/input/heartbeat\"\n",
        "TRAIN_CSV = os.path.join(DATA_PATH, \"mitbih_train.csv\")\n",
        "TEST_CSV  = os.path.join(DATA_PATH, \"mitbih_test.csv\")\n",
        "\n",
        "# It will read csv files using pandas\n",
        "train_df = pd.read_csv(TRAIN_CSV, header=None)\n",
        "test_df  = pd.read_csv(TEST_CSV, header=None)\n",
        "\n",
        "print(\" Dataset loaded successfully\")\n",
        "print(\"Train shape:\", train_df.shape)\n",
        "print(\"Test shape :\", test_df.shape)\n",
        "train_df.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T09:43:24.290933Z",
          "iopub.execute_input": "2025-12-06T09:43:24.291714Z",
          "iopub.status.idle": "2025-12-06T09:43:29.381438Z",
          "shell.execute_reply.started": "2025-12-06T09:43:24.291688Z",
          "shell.execute_reply": "2025-12-06T09:43:29.380564Z"
        },
        "id": "W4-WkKAbzdh4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Here we are creating a function to extract features from each ecg beat\n",
        "def extract_features_from_beat(beat):\n",
        "    x = np.asarray(beat).astype(float)\n",
        "    mean = np.mean(x); std = np.std(x)\n",
        "    mn, mx = np.min(x), np.max(x)\n",
        "    ptp = mx - mn\n",
        "    median = np.median(x)\n",
        "    q25, q75 = np.percentile(x, [25, 75])\n",
        "    iqr = q75 - q25\n",
        "    sk = skew(x); kurt = kurtosis(x)\n",
        "    rms = np.sqrt(np.mean(x**2))\n",
        "    energy = np.sum(x**2)\n",
        "    fft_mag = np.abs(np.fft.rfft(x))\n",
        "    fft_energy = np.sum(fft_mag**2)\n",
        "    peaks, props = find_peaks(x, height=np.mean(x)+0.2*np.std(x), distance=10)\n",
        "    num_peaks = len(peaks)\n",
        "    peak_heights = props['peak_heights'] if 'peak_heights' in props else np.array([0])\n",
        "    max_peak_height = np.max(peak_heights) if len(peak_heights)>0 else 0\n",
        "    idx_max = np.argmax(x)/len(x)\n",
        "\n",
        "    coeffs = pywt.wavedec(x, 'db4', level=3)\n",
        "    wa_mean, wd1_mean, wd2_mean, wd3_mean = [np.mean(c) for c in coeffs]\n",
        "    wa_std, wd1_std, wd2_std, wd3_std = [np.std(c) for c in coeffs]\n",
        "\n",
        "    diff1 = np.diff(x); diff2 = np.diff(diff1)\n",
        "    activity = np.var(x)\n",
        "    mobility = np.sqrt(np.var(diff1)/(activity+1e-8))\n",
        "    complexity = np.sqrt(np.var(diff2)/(np.var(diff1)+1e-8))/(mobility+1e-8)\n",
        "\n",
        "    return np.array([\n",
        "        mean,std,mn,mx,ptp,median,q25,q75,iqr,sk,kurt,rms,energy,fft_energy,\n",
        "        num_peaks,max_peak_height,idx_max,\n",
        "        wa_mean,wd1_mean,wd2_mean,wd3_mean,\n",
        "        wa_std,wd1_std,wd2_std,wd3_std,\n",
        "        activity,mobility,complexity\n",
        "    ])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T09:43:38.864287Z",
          "iopub.execute_input": "2025-12-06T09:43:38.865003Z",
          "iopub.status.idle": "2025-12-06T09:43:38.876818Z",
          "shell.execute_reply.started": "2025-12-06T09:43:38.864979Z",
          "shell.execute_reply": "2025-12-06T09:43:38.876135Z"
        },
        "id": "tumdWpbJzdh4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting all rows into feature matrices\n",
        "N_SAMPLES = train_df.shape[1] - 1\n",
        "\n",
        "def df_to_feature_matrix(df):\n",
        "    X, y = [], []\n",
        "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
        "        beat = row.iloc[:N_SAMPLES].values\n",
        "        label = int(row.iloc[N_SAMPLES])\n",
        "        X.append(extract_features_from_beat(beat))\n",
        "        y.append(label)\n",
        "    return np.vstack(X), np.array(y)\n",
        "\n",
        "X_train, y_train = df_to_feature_matrix(train_df)\n",
        "X_test,  y_test  = df_to_feature_matrix(test_df)\n",
        "\n",
        "print(\"Feature matrix shapes:\", X_train.shape,X_test.shape)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T09:43:45.574548Z",
          "iopub.execute_input": "2025-12-06T09:43:45.575085Z",
          "iopub.status.idle": "2025-12-06T09:46:59.557555Z",
          "shell.execute_reply.started": "2025-12-06T09:43:45.575064Z",
          "shell.execute_reply": "2025-12-06T09:46:59.556667Z"
        },
        "id": "64nS505dzdh4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Here we standardize all features so the mean= 0 and variance = 1 which helps models perform better\n",
        "scaler = StandardScaler()\n",
        "X_train_s = scaler.fit_transform(X_train)\n",
        "X_test_s  = scaler.transform(X_test)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T09:47:33.706199Z",
          "iopub.execute_input": "2025-12-06T09:47:33.7067Z",
          "iopub.status.idle": "2025-12-06T09:47:33.770419Z",
          "shell.execute_reply.started": "2025-12-06T09:47:33.706677Z",
          "shell.execute_reply": "2025-12-06T09:47:33.769569Z"
        },
        "id": "6leJBZ99zdh4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Train Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = rf.predict(X_test)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T09:47:39.124174Z",
          "iopub.execute_input": "2025-12-06T09:47:39.124745Z",
          "iopub.status.idle": "2025-12-06T09:49:40.319452Z",
          "shell.execute_reply.started": "2025-12-06T09:47:39.124721Z",
          "shell.execute_reply": "2025-12-06T09:49:40.31869Z"
        },
        "id": "eeb7feFmzdh5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.unique(y_test))\n",
        "disp.plot(cmap='Blues', values_format='d')\n",
        "plt.title(\"Random Forest Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "importances = rf.feature_importances_\n",
        "idx = np.argsort(importances)[::-1]\n",
        "feature_names = [\n",
        " 'mean','std','min','max','ptp','median','q25','q75','iqr','skew','kurtosis','rms',\n",
        " 'energy','fft_energy','num_peaks','max_peak_height','idx_max',\n",
        " 'wa_mean','wd1_mean','wd2_mean','wd3_mean',\n",
        " 'wa_std','wd1_std','wd2_std','wd3_std',\n",
        " 'activity','mobility','complexity'\n",
        "]\n",
        "print(\"Top 10 important features:\")\n",
        "for i in idx[:10]:\n",
        "    print(f\"{feature_names[i]:20s}: {importances[i]:.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T09:50:58.003784Z",
          "iopub.execute_input": "2025-12-06T09:50:58.004504Z",
          "iopub.status.idle": "2025-12-06T09:50:58.598337Z",
          "shell.execute_reply.started": "2025-12-06T09:50:58.004477Z",
          "shell.execute_reply": "2025-12-06T09:50:58.597697Z"
        },
        "id": "cXWD8Dlzzdh5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# We are using a random forest model\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=200,\n",
        "    class_weight='balanced',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "rf.fit(X_train_s, y_train)\n",
        "\n",
        "y_pred = rf.predict(X_test_s)\n",
        "\n",
        "print(\"Random Forest Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, digits=4))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T09:51:04.864567Z",
          "iopub.execute_input": "2025-12-06T09:51:04.865322Z",
          "iopub.status.idle": "2025-12-06T09:51:35.609676Z",
          "shell.execute_reply.started": "2025-12-06T09:51:04.865294Z",
          "shell.execute_reply": "2025-12-06T09:51:35.608971Z"
        },
        "id": "r1M8BeXfzdh6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Comparing with XGBoost and SVM\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgb = XGBClassifier(n_estimators=200, eval_metric='mlogloss', random_state=42, n_jobs=4)\n",
        "xgb.fit(X_train_s, y_train)\n",
        "y_pred_xgb = xgb.predict(X_test_s)\n",
        "print(\"\\nXGBoost Report:\")\n",
        "print(classification_report(y_test, y_pred_xgb, digits=4))\n",
        "\n",
        "svc = SVC(kernel='rbf', class_weight='balanced', random_state=42)\n",
        "svc.fit(X_train_s, y_train)\n",
        "y_pred_svc = svc.predict(X_test_s)\n",
        "print(\"\\nSVM Report:\")\n",
        "print(classification_report(y_test, y_pred_svc, digits=4))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T09:51:42.925801Z",
          "iopub.execute_input": "2025-12-06T09:51:42.92656Z",
          "iopub.status.idle": "2025-12-06T09:57:20.81566Z",
          "shell.execute_reply.started": "2025-12-06T09:51:42.926537Z",
          "shell.execute_reply": "2025-12-06T09:57:20.814983Z"
        },
        "id": "GsDBzb4ozdh6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Test prediction for a single heartbeat\n",
        "idx = 42\n",
        "beat = test_df.iloc[idx, :N_SAMPLES].values\n",
        "true_label = test_df.iloc[idx, N_SAMPLES]\n",
        "\n",
        "feat = extract_features_from_beat(beat).reshape(1, -1)\n",
        "feat_s = scaler.transform(feat)\n",
        "pred = rf.predict(feat_s)[0]\n",
        "\n",
        "plt.figure(figsize=(10,3))\n",
        "plt.plot(beat)\n",
        "plt.title(f\"Beat {idx} | True = {true_label} | Pred = {pred}\")\n",
        "plt.xlabel(\"Sample Index (0–186)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T09:57:57.175186Z",
          "iopub.execute_input": "2025-12-06T09:57:57.175814Z",
          "iopub.status.idle": "2025-12-06T09:57:57.354399Z",
          "shell.execute_reply.started": "2025-12-06T09:57:57.17579Z",
          "shell.execute_reply": "2025-12-06T09:57:57.353686Z"
        },
        "id": "KfhjJOyHzdh6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Upto now we did for just classifying normal amd abnormal\n",
        "# Now we are seeing for different types like for new born and people just before dying\n",
        "# Generating data for new born babies\n",
        "!pip install neurokit2 --quiet\n",
        "\n",
        "import neurokit2 as nk\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Generating  multiple newborn ECG signals\n",
        "signals = []\n",
        "for i in range(10):\n",
        "    ecg_signal = nk.ecg_simulate(duration=10, heart_rate=np.random.randint(120, 160), noise=0.01)\n",
        "    signals.append(ecg_signal)\n",
        "\n",
        "# Converting  to DataFrame\n",
        "newborn_df = pd.DataFrame(signals).T\n",
        "newborn_df.to_csv(\"newborn_ecg_dataset.csv\", index=False)\n",
        "\n",
        "print(\"Newborn ECG data generated and saved as newborn_ecg_dataset.csv\")\n",
        "\n",
        "# Visualizing one sample\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(signals[0])\n",
        "plt.title(\"Simulated Newborn ECG Signal (Fast Heart Rate)\")\n",
        "plt.xlabel(\"Time steps\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T09:58:01.705088Z",
          "iopub.execute_input": "2025-12-06T09:58:01.70536Z",
          "iopub.status.idle": "2025-12-06T09:58:08.638359Z",
          "shell.execute_reply.started": "2025-12-06T09:58:01.705341Z",
          "shell.execute_reply": "2025-12-06T09:58:08.63751Z"
        },
        "id": "l2TD4OLZzdh6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature extraction for newborn ECG\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import neurokit2 as nk\n",
        "from scipy.signal import find_peaks\n",
        "\n",
        "# Load the ECG dataset\n",
        "df = pd.read_csv(\"newborn_ecg_dataset.csv\")\n",
        "\n",
        "features = []\n",
        "\n",
        "for i in range(df.shape[1]):\n",
        "    signal = df.iloc[:, i].dropna().values\n",
        "\n",
        "\n",
        "    mean_val = np.mean(signal)\n",
        "    std_val = np.std(signal)\n",
        "    min_val = np.min(signal)\n",
        "    max_val = np.max(signal)\n",
        "\n",
        "    # Find peaks (QRS detection)\n",
        "    peaks, _ = find_peaks(signal, distance=50)\n",
        "    peak_count = len(peaks)\n",
        "\n",
        "    # Approx heart rate (peaks per 10s * 6 → bpm)\n",
        "    heart_rate = (peak_count / 10) * 60\n",
        "\n",
        "    # Stores all features\n",
        "    features.append([mean_val, std_val, min_val, max_val, peak_count, heart_rate])\n",
        "\n",
        "# Create feature DataFrame\n",
        "feature_df = pd.DataFrame(features, columns=[\"mean\", \"std\", \"min\", \"max\", \"peak_count\", \"heart_rate\"])\n",
        "feature_df.to_csv(\"newborn_features.csv\", index=False)\n",
        "\n",
        "print(\"Feature extraction done\")\n",
        "print(feature_df.head())\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T09:58:15.474418Z",
          "iopub.execute_input": "2025-12-06T09:58:15.475277Z",
          "iopub.status.idle": "2025-12-06T09:58:15.515144Z",
          "shell.execute_reply.started": "2025-12-06T09:58:15.47525Z",
          "shell.execute_reply": "2025-12-06T09:58:15.514553Z"
        },
        "id": "lQ5z1gFdzdh6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a Random Forest model on newborn ECG features\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load feature data\n",
        "df = pd.read_csv(\"newborn_features.csv\")\n",
        "\n",
        "# For now, create dummy labels (you can later replace with real labels)\n",
        "# Suppose we later collect some abnormal newborn data — we'll label it as 1.\n",
        "# For now all normal newborn => label 0\n",
        "y = np.zeros(len(df))\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Random Forest\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "print(\" Model trained successfully\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(cm)\n",
        "disp.plot()\n",
        "plt.title(\"Newborn ECG Random Forest Model — Confusion Matrix\")\n",
        "plt.show()\n",
        "import joblib\n",
        "joblib.dump(model, \"ecg_4class_model.pkl\")\n",
        "\n",
        "print(\"Model saved as ecg_4class_model.pkl\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T09:58:20.69408Z",
          "iopub.execute_input": "2025-12-06T09:58:20.694696Z",
          "iopub.status.idle": "2025-12-06T09:58:21.00019Z",
          "shell.execute_reply.started": "2025-12-06T09:58:20.694671Z",
          "shell.execute_reply": "2025-12-06T09:58:20.99942Z"
        },
        "id": "N6IZfvbdzdh6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#  Generating synthetic pre-death ECG signal\n",
        "import neurokit2 as nk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generating multiple pre-death ECG signals\n",
        "signals = []\n",
        "for i in range(10):\n",
        "    ecg_signal = nk.ecg_simulate(duration=10, heart_rate=np.random.randint(25, 40), noise=0.05)\n",
        "\n",
        "    # Reduce amplitude to mimic weak cardiac activity\n",
        "    ecg_signal = ecg_signal * np.random.uniform(0.3, 0.6)\n",
        "\n",
        "    # Adding small irregularity\n",
        "    ecg_signal += np.random.normal(0, 0.005, len(ecg_signal))\n",
        "\n",
        "    signals.append(ecg_signal)\n",
        "\n",
        "# Converting to DataFrame\n",
        "predeath_df = pd.DataFrame(signals).T\n",
        "predeath_df.to_csv(\"predeath_ecg_dataset.csv\", index=False)\n",
        "\n",
        "print(\" Pre-death ECG data generated and saved as predeath_ecg_dataset.csv\")\n",
        "\n",
        "# Visualizing one sample\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(signals[0])\n",
        "plt.title(\"Simulated Pre-death ECG Signal (Weak, Low Heart Rate)\")\n",
        "plt.xlabel(\"Time steps\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T09:58:27.065447Z",
          "iopub.execute_input": "2025-12-06T09:58:27.065805Z",
          "iopub.status.idle": "2025-12-06T09:58:28.437267Z",
          "shell.execute_reply.started": "2025-12-06T09:58:27.065784Z",
          "shell.execute_reply": "2025-12-06T09:58:28.436513Z"
        },
        "id": "-2rokwqizdh6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature extraction for Pre-death ECG\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.signal import find_peaks\n",
        "\n",
        "# Load the ECG dataset\n",
        "df = pd.read_csv(\"predeath_ecg_dataset.csv\")\n",
        "\n",
        "features = []\n",
        "\n",
        "for i in range(df.shape[1]):\n",
        "    signal = df.iloc[:, i].dropna().values\n",
        "\n",
        "    # Basic statistical features\n",
        "    mean_val = np.mean(signal)\n",
        "    std_val = np.std(signal)\n",
        "    min_val = np.min(signal)\n",
        "    max_val = np.max(signal)\n",
        "\n",
        "    # Detect peaks (QRS complexes)\n",
        "    peaks, _ = find_peaks(signal, distance=50)\n",
        "    peak_count = len(peaks)\n",
        "\n",
        "    # Approx heart rate\n",
        "    heart_rate = (peak_count / 10) * 60\n",
        "\n",
        "    features.append([mean_val, std_val, min_val, max_val, peak_count, heart_rate])\n",
        "\n",
        "# Create DataFrame\n",
        "predeath_features = pd.DataFrame(features, columns=[\"mean\", \"std\", \"min\", \"max\", \"peak_count\", \"heart_rate\"])\n",
        "predeath_features.to_csv(\"predeath_features.csv\", index=False)\n",
        "\n",
        "print(\"Pre-death ECG features extracted and saved as predeath_features.csv\")\n",
        "print(predeath_features.head())\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T09:58:34.150948Z",
          "iopub.execute_input": "2025-12-06T09:58:34.151419Z",
          "iopub.status.idle": "2025-12-06T09:58:34.188112Z",
          "shell.execute_reply.started": "2025-12-06T09:58:34.151395Z",
          "shell.execute_reply": "2025-12-06T09:58:34.187486Z"
        },
        "id": "n74WZ8W5zdh6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Combines newborn and pre-death datasets and train classifier\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Loads features\n",
        "newborn = pd.read_csv(\"newborn_features.csv\")\n",
        "predeath = pd.read_csv(\"predeath_features.csv\")\n",
        "\n",
        "# Add class labels\n",
        "newborn[\"label\"] = 0  # newborn\n",
        "predeath[\"label\"] = 1  # pre-death\n",
        "\n",
        "# Combine datasets\n",
        "data = pd.concat([newborn, predeath], ignore_index=True)\n",
        "\n",
        "# Split features and labels\n",
        "X = data.drop(columns=[\"label\"])\n",
        "y = data[\"label\"]\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Train Random Forest model\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "print(\" Model trained: Newborn vs Pre-death ECGs\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=[\"Newborn\", \"Pre-death\"]))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(cm, display_labels=[\"Newborn\", \"Pre-death\"])\n",
        "disp.plot()\n",
        "plt.title(\"Confusion Matrix — Newborn vs Pre-death ECGs\")\n",
        "plt.show()\n",
        "\n",
        "# Feature Importance\n",
        "importances = model.feature_importances_\n",
        "plt.figure(figsize=(7,4))\n",
        "plt.bar(X.columns, importances)\n",
        "plt.title(\"Feature Importance — Newborn vs Pre-death ECGs\")\n",
        "plt.ylabel(\"Importance\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T09:58:38.08917Z",
          "iopub.execute_input": "2025-12-06T09:58:38.089772Z",
          "iopub.status.idle": "2025-12-06T09:58:38.503724Z",
          "shell.execute_reply.started": "2025-12-06T09:58:38.08975Z",
          "shell.execute_reply": "2025-12-06T09:58:38.50305Z"
        },
        "id": "LBMPjWzdzdh6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate synthetic Coma ECG signals\n",
        "import neurokit2 as nk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "signals = []\n",
        "n_samples = 20\n",
        "duration = 10\n",
        "\n",
        "for i in range(n_samples):\n",
        "    ecg = nk.ecg_simulate(duration=duration, heart_rate=np.random.randint(35, 50), noise=0.01)\n",
        "\n",
        "    ecg = ecg * np.random.uniform(0.3, 0.6)\n",
        "    ecg = nk.signal_smooth(ecg, method=\"convolution\", size=20)\n",
        "\n",
        "    signals.append(ecg)\n",
        "\n",
        "coma_df = pd.DataFrame(signals).T\n",
        "coma_df.to_csv(\"coma_ecg_dataset.csv\", index=False)\n",
        "\n",
        "print(\"Coma ECG dataset saved as coma_ecg_dataset.csv\")\n",
        "\n",
        "# Plot example\n",
        "plt.plot(signals[0])\n",
        "plt.title(\"Example: Coma ECG Signal\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T09:58:50.284726Z",
          "iopub.execute_input": "2025-12-06T09:58:50.285297Z",
          "iopub.status.idle": "2025-12-06T09:58:53.001203Z",
          "shell.execute_reply.started": "2025-12-06T09:58:50.285277Z",
          "shell.execute_reply": "2025-12-06T09:58:53.000416Z"
        },
        "id": "Yn4LiSxPzdh7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature extraction for coma ECG signals\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.signal import find_peaks\n",
        "\n",
        "df = pd.read_csv(\"coma_ecg_dataset.csv\")\n",
        "\n",
        "features = []\n",
        "\n",
        "for i in range(df.shape[1]):\n",
        "    sig = df.iloc[:, i].dropna().values\n",
        "\n",
        "    mean_val = np.mean(sig)\n",
        "    std_val = np.std(sig)\n",
        "    min_val = np.min(sig)\n",
        "    max_val = np.max(sig)\n",
        "\n",
        "    # Peak detection\n",
        "    peaks, _ = find_peaks(sig, distance=50)\n",
        "    peak_count = len(peaks)\n",
        "\n",
        "    heart_rate = (peak_count / 10) * 60\n",
        "\n",
        "    features.append([mean_val, std_val, min_val, max_val, peak_count, heart_rate])\n",
        "\n",
        "coma_features = pd.DataFrame(features, columns=[\"mean\",\"std\",\"min\",\"max\",\"peak_count\",\"heart_rate\"])\n",
        "coma_features.to_csv(\"coma_features.csv\", index=False)\n",
        "\n",
        "print(\"Coma features saved as coma_features.csv\")\n",
        "print(coma_features.head())\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T09:59:00.710436Z",
          "iopub.execute_input": "2025-12-06T09:59:00.710964Z",
          "iopub.status.idle": "2025-12-06T09:59:00.775012Z",
          "shell.execute_reply.started": "2025-12-06T09:59:00.710943Z",
          "shell.execute_reply": "2025-12-06T09:59:00.774072Z"
        },
        "id": "jLbU7PQZzdh7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating Mental/Stress ECG signals\n",
        "import neurokit2 as nk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "signals = []\n",
        "n_samples = 20\n",
        "duration = 10\n",
        "\n",
        "for i in range(n_samples):\n",
        "    hr = np.random.randint(90, 130)\n",
        "    ecg = nk.ecg_simulate(duration=duration, heart_rate=hr, noise=np.random.uniform(0.02, 0.06))\n",
        "\n",
        "    # Add occasional random spikes (stress arrhythmia)\n",
        "    if np.random.rand() < 0.5:\n",
        "        idx = np.random.randint(0, len(ecg))\n",
        "        spike_mag = np.random.uniform(0.05, 0.15)\n",
        "        spike_width = np.random.randint(3, 15)\n",
        "        start = max(0, idx - spike_width//2)\n",
        "        end = min(len(ecg), start + spike_width)\n",
        "        spike = spike_mag * np.exp(-((np.arange(start,end)-idx)**2)/(2*(spike_width/4)**2))\n",
        "        ecg[start:end] += spike\n",
        "\n",
        "    ecg *= np.random.uniform(0.8, 1.2)\n",
        "    signals.append(ecg)\n",
        "\n",
        "mental_df = pd.DataFrame(signals).T\n",
        "mental_df.to_csv(\"mental_ecg_dataset.csv\", index=False)\n",
        "\n",
        "print(\"Mental/Stress ECG dataset saved as mental_ecg_dataset.csv\")\n",
        "\n",
        "plt.plot(signals[0])\n",
        "plt.title(\"Example: Mental/Stress ECG\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T09:59:05.624355Z",
          "iopub.execute_input": "2025-12-06T09:59:05.624665Z",
          "iopub.status.idle": "2025-12-06T09:59:10.037183Z",
          "shell.execute_reply.started": "2025-12-06T09:59:05.624641Z",
          "shell.execute_reply": "2025-12-06T09:59:10.036472Z"
        },
        "id": "O1VHOmlyzdh7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature extraction for mental/stress ECG\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.signal import find_peaks\n",
        "\n",
        "df = pd.read_csv(\"mental_ecg_dataset.csv\")\n",
        "\n",
        "features = []\n",
        "\n",
        "for i in range(df.shape[1]):\n",
        "    sig = df.iloc[:, i].dropna().values\n",
        "\n",
        "    mean_val = np.mean(sig)\n",
        "    std_val = np.std(sig)\n",
        "    min_val = np.min(sig)\n",
        "    max_val = np.max(sig)\n",
        "\n",
        "    peaks, _ = find_peaks(sig, distance=50)\n",
        "    peak_count = len(peaks)\n",
        "\n",
        "    heart_rate = (peak_count / 10) * 60\n",
        "\n",
        "    features.append([mean_val, std_val, min_val, max_val, peak_count, heart_rate])\n",
        "\n",
        "mental_features = pd.DataFrame(features, columns=[\"mean\",\"std\",\"min\",\"max\",\"peak_count\",\"heart_rate\"])\n",
        "mental_features.to_csv(\"mental_features.csv\", index=False)\n",
        "\n",
        "print(\"Mental features saved as mental_features.csv\")\n",
        "print(mental_features.head())\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T09:59:18.994487Z",
          "iopub.execute_input": "2025-12-06T09:59:18.995231Z",
          "iopub.status.idle": "2025-12-06T09:59:19.055676Z",
          "shell.execute_reply.started": "2025-12-06T09:59:18.995206Z",
          "shell.execute_reply": "2025-12-06T09:59:19.055043Z"
        },
        "id": "ZUuXfPP0zdh7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        " #Multi-class classification for all 4 ECG types\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load feature sets\n",
        "newborn = pd.read_csv(\"newborn_features.csv\"); newborn[\"label\"] = 0\n",
        "predeath = pd.read_csv(\"predeath_features.csv\"); predeath[\"label\"] = 1\n",
        "coma = pd.read_csv(\"coma_features.csv\"); coma[\"label\"] = 2\n",
        "mental = pd.read_csv(\"mental_features.csv\"); mental[\"label\"] = 3\n",
        "\n",
        "# Combine all classes\n",
        "data = pd.concat([newborn, predeath, coma, mental], ignore_index=True)\n",
        "\n",
        "X = data.drop(columns=[\"label\"])\n",
        "y = data[\"label\"]\n",
        "\n",
        "# Split (stratified)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,\n",
        "                                                    random_state=42, stratify=y)\n",
        "\n",
        "# Train Random Forest\n",
        "model = RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"4-Class ECG Model Trained Successfully\\n\")\n",
        "print(classification_report(y_test, y_pred,\n",
        "                            target_names=[\"Newborn\",\"Dying\",\"Coma\",\"Mental\"]))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(cm, display_labels=[\"Newborn\",\"Dying\",\"Coma\",\"Mental\"])\n",
        "disp.plot(cmap=\"Blues\")\n",
        "plt.title(\"Confusion Matrix — 4-Class ECG Classification\")\n",
        "plt.show()\n",
        "\n",
        "# Feature Importance\n",
        "importances = model.feature_importances_\n",
        "plt.bar(X.columns, importances)\n",
        "plt.title(\"Feature Importance Across All 4 ECG Conditions\")\n",
        "plt.ylabel(\"Importance\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T09:59:23.532284Z",
          "iopub.execute_input": "2025-12-06T09:59:23.532557Z",
          "iopub.status.idle": "2025-12-06T09:59:24.077294Z",
          "shell.execute_reply.started": "2025-12-06T09:59:23.532538Z",
          "shell.execute_reply": "2025-12-06T09:59:24.076646Z"
        },
        "id": "T9CfBiv0zdh-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.signal import find_peaks\n",
        "\n",
        "# Load trained model\n",
        "model = joblib.load(\"ecg_4class_model.pkl\")\n",
        "\n",
        "print(\"Model loaded successfully!\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T09:59:30.421511Z",
          "iopub.execute_input": "2025-12-06T09:59:30.422282Z",
          "iopub.status.idle": "2025-12-06T09:59:30.449562Z",
          "shell.execute_reply.started": "2025-12-06T09:59:30.422257Z",
          "shell.execute_reply": "2025-12-06T09:59:30.448984Z"
        },
        "id": "T4EYyys9zdh_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_ecg_features(signal, duration_seconds=10):\n",
        "    signal = np.array(signal).astype(float)\n",
        "\n",
        "    mean_val = np.mean(signal)\n",
        "    std_val = np.std(signal)\n",
        "    min_val = np.min(signal)\n",
        "    max_val = np.max(signal)\n",
        "\n",
        "    # Peak detection (same as training)\n",
        "    peaks, _ = find_peaks(signal, distance=50)\n",
        "    peak_count = len(peaks)\n",
        "\n",
        "    # Heart rate estimation\n",
        "    heart_rate = (peak_count / duration_seconds) * 60\n",
        "\n",
        "    return np.array([mean_val, std_val, min_val, max_val, peak_count, heart_rate]).reshape(1, -1)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T09:59:35.319065Z",
          "iopub.execute_input": "2025-12-06T09:59:35.319768Z",
          "iopub.status.idle": "2025-12-06T09:59:35.324309Z",
          "shell.execute_reply.started": "2025-12-06T09:59:35.319744Z",
          "shell.execute_reply": "2025-12-06T09:59:35.323514Z"
        },
        "id": "-k3s5HXOzdh_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_ecg(signal):\n",
        "    features = extract_ecg_features(signal)\n",
        "\n",
        "    pred = model.predict(features)[0]\n",
        "\n",
        "    label_map = {\n",
        "        0: \"Newborn\",\n",
        "        1: \"Dying/Pre-death\",\n",
        "        2: \"Coma Patient\",\n",
        "        3: \"Mental/Stress Patient\"\n",
        "    }\n",
        "\n",
        "    return label_map[pred]\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T09:59:39.084147Z",
          "iopub.execute_input": "2025-12-06T09:59:39.084398Z",
          "iopub.status.idle": "2025-12-06T09:59:39.088796Z",
          "shell.execute_reply.started": "2025-12-06T09:59:39.084381Z",
          "shell.execute_reply": "2025-12-06T09:59:39.087989Z"
        },
        "id": "I8xJQuIPzdh_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import time, os, sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.signal import find_peaks\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# -------------- Config --------------\n",
        "FILES = {\n",
        "    \"newborn\": \"newborn_features.csv\",\n",
        "    \"dying\":   \"predeath_features.csv\",\n",
        "    \"coma\":    \"coma_features.csv\",\n",
        "    \"mental\":  \"mental_features.csv\",\n",
        "}\n",
        "LABEL_MAP = {0: \"Newborn\", 1: \"Dying/Pre-death\", 2: \"Coma Patient\", 3: \"Mental/Stress Patient\"}\n",
        "MIN_LEN = 80          # minimal length for peak detection (tile if shorter)\n",
        "DURATION_SECONDS = 10.0  # used to estimate bpm; adjust if your input length differs\n",
        "\n",
        "# -------------- quick file check --------------\n",
        "missing = [v for v in FILES.values() if not os.path.isfile(v)]\n",
        "if missing:\n",
        "    print(\"ERROR: Missing feature files:\", missing)\n",
        "    print(\"Make sure these files exist in the notebook working directory.\")\n",
        "    raise FileNotFoundError(f\"Missing: {missing}\")\n",
        "\n",
        "# -------------- load and combine feature CSVs (very small) --------------\n",
        "dfs = []\n",
        "for i,(k,fname) in enumerate(FILES.items()):\n",
        "    df = pd.read_csv(fname)\n",
        "    df = df.copy()\n",
        "    df['label'] = i   # 0,1,2,3 mapping\n",
        "    dfs.append(df)\n",
        "data = pd.concat(dfs, ignore_index=True)\n",
        "X = data.drop(columns=['label']).values\n",
        "y = data['label'].values\n",
        "\n",
        "# -------------- train tiny logistic model (fast) --------------\n",
        "t0 = time.time()\n",
        "# Use a tiny pipeline with scaling + logistic regression (liblinear solver is quick on small data)\n",
        "clf = make_pipeline(StandardScaler(), LogisticRegression(multi_class='ovr', solver='liblinear', C=1.0, max_iter=200, random_state=42))\n",
        "clf.fit(X, y)\n",
        "t1 = time.time()\n",
        "print(f\"Trained lightweight classifier in {t1-t0:.2f}s (fast).\")\n",
        "\n",
        "# -------------- fast feature extractor (numpy-only) --------------\n",
        "def extract_features_fast(sig, duration_seconds=DURATION_SECONDS):\n",
        "    sig = np.asarray(sig, dtype=float)\n",
        "    sig = sig[~np.isnan(sig)]\n",
        "    if sig.size == 0:\n",
        "        raise ValueError(\"Signal empty after removing NaNs.\")\n",
        "    mean_val = float(sig.mean())\n",
        "    std_val  = float(sig.std())\n",
        "    min_val  = float(sig.min())\n",
        "    max_val  = float(sig.max())\n",
        "    # peak distance scaled to signal length (safe)\n",
        "    distance = max(3, int(len(sig) * 0.05))\n",
        "    peaks, _ = find_peaks(sig, distance=distance)\n",
        "    peak_count = int(peaks.size)\n",
        "    est_bpm = float((peak_count / duration_seconds) * 60.0)\n",
        "    return np.array([mean_val, std_val, min_val, max_val, peak_count, est_bpm], dtype=float)\n",
        "\n",
        "# -------------- input parsing helper (very fast) --------------\n",
        "def parse_input_to_signal(raw_text, min_len=MIN_LEN):\n",
        "    toks = [t for t in raw_text.replace(',', ' ').split() if t!='']\n",
        "    if len(toks) == 0:\n",
        "        raise ValueError(\"No numeric tokens found. Provide numbers separated by spaces or commas.\")\n",
        "    try:\n",
        "        arr = np.array([float(x) for x in toks], dtype=float)\n",
        "    except Exception as e:\n",
        "        raise ValueError(\"Failed to parse numbers. Use floats separated by commas or spaces.\") from e\n",
        "    if arr.size < min_len:\n",
        "        reps = int(np.ceil(min_len / max(1, arr.size)))\n",
        "        arr = np.tile(arr, reps)[:min_len]\n",
        "    return arr\n",
        "\n",
        "# -------------- interactive prompt (simple & fast) --------------\n",
        "print(\"\\nNow paste ECG values (comma or space separated). Short inputs auto-extended to ~80 samples for detection.\")\n",
        "raw = input(\"Enter ECG values:\\n\").strip()\n",
        "start = time.time()\n",
        "try:\n",
        "    sig = parse_input_to_signal(raw)\n",
        "    feats = extract_features_fast(sig).reshape(1,-1)\n",
        "    pred = clf.predict(feats)[0]\n",
        "    probs = clf.predict_proba(feats)[0] if hasattr(clf, \"predict_proba\") else None\n",
        "    elapsed = time.time() - start\n",
        "    print(f\"\\n Predicted: {LABEL_MAP.get(int(pred),'Class'+str(pred))}  (in {elapsed*1000:.1f} ms)\")\n",
        "    if probs is not None:\n",
        "        # print compact probabilities\n",
        "        for i,p in enumerate(probs):\n",
        "            print(f\"  {LABEL_MAP.get(i)}: {p*100:5.1f}%\")\n",
        "    # show features (small)\n",
        "    print(\"\\nFeatures used: mean, std, min, max, peak_count, est_bpm\")\n",
        "    print(np.round(feats.flatten(), 4))\n",
        "except Exception as e:\n",
        "    print(\"ERROR during prediction:\", e)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-06T10:03:05.839298Z",
          "iopub.execute_input": "2025-12-06T10:03:05.839781Z",
          "iopub.status.idle": "2025-12-06T10:04:54.738392Z",
          "shell.execute_reply.started": "2025-12-06T10:03:05.839761Z",
          "shell.execute_reply": "2025-12-06T10:04:54.737712Z"
        },
        "id": "RCSuSXMMzdh_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "4OFqmFHizdh_"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}